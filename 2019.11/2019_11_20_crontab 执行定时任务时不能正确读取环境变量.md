### 爬虫定时任务不能正常工作

#### 一句话总结：需要依赖变量的cron任务，请务必指定环境变量

我的爬虫任务是通过crontab来进行调度的。爬虫是通过运行在虚拟环境中的，通过sh命令启动。代码如下：


```
# 文件名task.sh
source data_venv/bin/activate
python spider.py
python parser.py
deactivate
```

cron任务是这样写的：
```
0 */2 * * * cd /data/Blog_Data/ && bash task.sh
```

看起来没有问题，但是任务就是无法执行。
起初我以为我的Cron命令写的有问题，反复比较之后，确定命令没有问题。
通过Google一番，很多答案都说是cron服务可能有问题，遂去查看。

```
# 查看cron服务状态
service crond status

# 状态输出
● crond.service - Command Scheduler
   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2019-11-15 15:51:55 CST; 5 days ago
```
服务是正常的，所以排除了cron服务的问题。

再去看cron服务的日志

```
Nov 15 04:00:01 VM_0_8_centos CROND[5672]: (root) CMD (cd /data/Blog_Data/ && ./task.sh)
```
看起来也是正常，没有报错信息，看起来也正常执行了。

到这里我就有点懵逼了，为什么没有反应？既没有报错，但是也没有正常执行。
冷静下来想，肯定是哪里错了，但是一时半会也没有解决问题思路，抱着试一试的态度，给cron新增了日志记录，并指定了输出目录，如下：

```
0 */2 * * * cd /data/Blog_Data/ && bash task.sh >> /data/log/spider/mylog.log 2>&1
```
这回运行，看到了报错信息：
```
# XXX是我线下数据库的表名
psycopg2.OperationalError: FATAL:  database "XXX" does not exist
```
恍然发现，原来是cron在执行虚拟环境中的任务时，没有正确读取环境变量。

至此，问题就比较清楚了，google在cron中配置环境变量的方式。
stackoverflow 上有答案给出了好几种配置的方式，我选择了一种我比较能够理解的方式。
stackoverflow 上该问题地址：https://stackoverflow.com/questions/2229825/where-can-i-set-environment-variables-that-crontab-will-use

11月25日更新
后来又去研究了一下Linux上环境变量的配置问题，我下面这种操作方式，相当于临时新建了环境变量，在任务执行完成之后，即会被丢弃。个人更喜欢这种操作方式。

```
#!/bin/sh
export FLASK_ENVIRONMENT=production
export FLASK_ENV=production
source data_venv/bin/activate
python spider.py
python parser.py
deactivate
```

配置完成后，发现任务可以正常执行了。问题得到解决！